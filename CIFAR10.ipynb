{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label is encoded, 0-9, representing a class. Each image is a 3072 length array. The images are 32x32, so the first 1024 values correspond to the red channel, followed by the green and the red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.313296Z",
     "start_time": "2019-03-19T17:25:35.016219Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from skimage import io, transform\n",
    "from torchvision import utils, transforms\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.318617Z",
     "start_time": "2019-03-19T17:25:36.315944Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.326587Z",
     "start_time": "2019-03-19T17:25:36.320587Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.376294Z",
     "start_time": "2019-03-19T17:25:36.329236Z"
    }
   },
   "outputs": [],
   "source": [
    "data = unpickle('cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.381781Z",
     "start_time": "2019-03-19T17:25:36.379331Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data[b'labels']\n",
    "y = data[b'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.452956Z",
     "start_time": "2019-03-19T17:25:36.384055Z"
    }
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "               \n",
    "        return {'image': img, 'label': label}\n",
    "    \n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, h-new_h)\n",
    "        left = np.random.randint(0, w-new_w)\n",
    "        \n",
    "        image = image[top: top+new_h,\n",
    "                      left: left+new_w]\n",
    "        \n",
    "        return {'image': image, 'label': label}\n",
    "    \n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        # swap color axis because\n",
    "        # numpy iamge: HxWxC\n",
    "        # torch image: CxHxW\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.463571Z",
     "start_time": "2019-03-19T17:25:36.456022Z"
    }
   },
   "outputs": [],
   "source": [
    "class CIFARDataset(Dataset):\n",
    "    def __init__(self, batch_lst:list, transform=None):\n",
    "        \"\"\"To be used when iterating over the \n",
    "        files within the root directory\"\"\"\n",
    "        self.labels, self.images = [], []\n",
    "        \n",
    "        for file in batch_lst:\n",
    "            data = unpickle(file)\n",
    "            self.labels += data[b'labels']\n",
    "            self.images += [cifar10_to_rgb(img) for img in data[b'data']]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> dict:\n",
    "        \"\"\"For any index in the range of img_lst\n",
    "        it maps image to the image values\n",
    "        and species to the type of bird\"\"\"\n",
    "        sample = {'image': self.images[idx], \n",
    "                  'label': self.labels[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:25:36.470032Z",
     "start_time": "2019-03-19T17:25:36.465856Z"
    }
   },
   "outputs": [],
   "source": [
    "def cifar10_to_rgb(arr_lst):\n",
    "    ___ = []\n",
    "    for k in range(32):\n",
    "        __ = []\n",
    "        for j in range(32):\n",
    "            _ = []\n",
    "            for i in range(3):\n",
    "                _ += [arr_lst[1024*i+32*j+k]]\n",
    "            __ += [_]\n",
    "        ___ += [__]\n",
    "    return np.array(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:26:54.068591Z",
     "start_time": "2019-03-19T17:25:36.472996Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_lst = \"\"\"cifar-10-batches-py/data_batch_1\n",
    "               cifar-10-batches-py/data_batch_2\n",
    "               cifar-10-batches-py/data_batch_3\n",
    "               cifar-10-batches-py/data_batch_4\n",
    "               cifar-10-batches-py/data_batch_5\n",
    "            \"\"\".split()\n",
    "\n",
    "CIFAR = CIFARDataset(batch_lst,\n",
    "                     transform=transforms.Compose([\n",
    "#                                       Rescale(256),\n",
    "                                      RandomCrop(30),\n",
    "                                      ToTensor()\n",
    "                                  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:26:54.567620Z",
     "start_time": "2019-03-19T17:26:54.070934Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(CIFAR, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Data Loader to Implement Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T17:26:54.572755Z",
     "start_time": "2019-03-19T17:26:54.570071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4,\n",
    "                              shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4,\n",
    "                             shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:01:35.834181Z",
     "start_time": "2019-03-19T18:01:35.822126Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, dropout_rate=0):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 6, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, 6, padding=1)\n",
    "        self.fc1 = nn.Linear(12*5*5, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))        \n",
    "        x = x.view(-1, 12*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:01:36.396693Z",
     "start_time": "2019-03-19T18:01:36.393212Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, \n",
    "                      momentum=0.9)#, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train For Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:01:36.904850Z",
     "start_time": "2019-03-19T18:01:36.896918Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epocs):\n",
    "    losses = []\n",
    "    for epoch in range(num_epocs):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            inputs = data['image'].float()\n",
    "            labels = data['label']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses += [loss.item()]\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 999:\n",
    "                print(f'[{epoch+1}, {i+1}] loss: {running_loss/1000}')\n",
    "                running_loss = 0.0\n",
    "        test()\n",
    "\n",
    "                \n",
    "def test():\n",
    "    losses = []\n",
    "    net.eval()\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        inputs = data['image'].float()\n",
    "        labels = data['label']\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses += [loss.item()]\n",
    "    print(f'Test Loss: {np.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:08:39.562922Z",
     "start_time": "2019-03-19T18:01:37.857704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] loss: 2.2939008927345275\n",
      "[1, 2000] loss: 2.1241402662992477\n",
      "[1, 3000] loss: 2.032047041296959\n",
      "[1, 4000] loss: 1.9511365410089492\n",
      "[1, 5000] loss: 1.8825261654257774\n",
      "[1, 6000] loss: 1.850749166548252\n",
      "[1, 7000] loss: 1.8128227937221526\n",
      "[1, 8000] loss: 1.7780043205618858\n",
      "[1, 9000] loss: 1.7489470357894898\n",
      "Test Loss: 1.7463831238365173\n",
      "[2, 1000] loss: 1.7063379893898964\n",
      "[2, 2000] loss: 1.6882118046879768\n",
      "[2, 3000] loss: 1.686789938688278\n",
      "[2, 4000] loss: 1.6517485678791999\n",
      "[2, 5000] loss: 1.6780622035861015\n",
      "[2, 6000] loss: 1.675162107884884\n",
      "[2, 7000] loss: 1.6032831273674966\n",
      "[2, 8000] loss: 1.6278938120007516\n",
      "[2, 9000] loss: 1.6340268864035605\n",
      "Test Loss: 1.6140663200187684\n",
      "[3, 1000] loss: 1.5913055840432644\n",
      "[3, 2000] loss: 1.6013480325341225\n",
      "[3, 3000] loss: 1.558751403450966\n",
      "[3, 4000] loss: 1.564589849948883\n",
      "[3, 5000] loss: 1.5612137846648693\n",
      "[3, 6000] loss: 1.6119517208337784\n",
      "[3, 7000] loss: 1.555200392127037\n",
      "[3, 8000] loss: 1.5496837377548218\n",
      "[3, 9000] loss: 1.546994085609913\n",
      "Test Loss: 1.5376763193511962\n",
      "[4, 1000] loss: 1.5283411682844161\n",
      "[4, 2000] loss: 1.5193885908126832\n",
      "[4, 3000] loss: 1.531626551270485\n",
      "[4, 4000] loss: 1.5353067142367363\n",
      "[4, 5000] loss: 1.5035881357192993\n",
      "[4, 6000] loss: 1.5282943959832191\n",
      "[4, 7000] loss: 1.5057247830033302\n",
      "[4, 8000] loss: 1.4840335515737533\n",
      "[4, 9000] loss: 1.4985708110928535\n",
      "Test Loss: 1.5313920573425293\n",
      "[5, 1000] loss: 1.4669821811914443\n",
      "[5, 2000] loss: 1.445233065187931\n",
      "[5, 3000] loss: 1.4827434115707874\n",
      "[5, 4000] loss: 1.442020644903183\n",
      "[5, 5000] loss: 1.4663023863434792\n",
      "[5, 6000] loss: 1.4685280768573283\n",
      "[5, 7000] loss: 1.4752098442018031\n",
      "[5, 8000] loss: 1.437573496580124\n",
      "[5, 9000] loss: 1.464092750787735\n",
      "Test Loss: 1.4558497895622253\n",
      "[6, 1000] loss: 1.4121784487366675\n",
      "[6, 2000] loss: 1.41875101095438\n",
      "[6, 3000] loss: 1.4002144420444966\n",
      "[6, 4000] loss: 1.4411279773414134\n",
      "[6, 5000] loss: 1.4219313102066518\n",
      "[6, 6000] loss: 1.3767353786826133\n",
      "[6, 7000] loss: 1.3730137937366962\n",
      "[6, 8000] loss: 1.4480446787178516\n",
      "[6, 9000] loss: 1.4227316310703755\n",
      "Test Loss: 1.453385532131195\n",
      "[7, 1000] loss: 1.3822645935714244\n",
      "[7, 2000] loss: 1.3415617097318173\n",
      "[7, 3000] loss: 1.3838412062823773\n",
      "[7, 4000] loss: 1.3701250824332236\n",
      "[7, 5000] loss: 1.3951295414268972\n",
      "[7, 6000] loss: 1.3905861396789552\n",
      "[7, 7000] loss: 1.3508395927846433\n",
      "[7, 8000] loss: 1.3792441303730012\n",
      "[7, 9000] loss: 1.382119007050991\n",
      "Test Loss: 1.432148990545273\n",
      "[8, 1000] loss: 1.3305179827213287\n",
      "[8, 2000] loss: 1.3456883642077446\n",
      "[8, 3000] loss: 1.3275671128034592\n",
      "[8, 4000] loss: 1.3249856439232826\n",
      "[8, 5000] loss: 1.335522367209196\n",
      "[8, 6000] loss: 1.3357156143188476\n",
      "[8, 7000] loss: 1.3204722965359688\n",
      "[8, 8000] loss: 1.3710124758183957\n",
      "[8, 9000] loss: 1.3467844858765603\n",
      "Test Loss: 1.4103839718055724\n",
      "[9, 1000] loss: 1.3165677276551724\n",
      "[9, 2000] loss: 1.3206426414251327\n",
      "[9, 3000] loss: 1.295265242666006\n",
      "[9, 4000] loss: 1.3187021190226078\n",
      "[9, 5000] loss: 1.2838045492768289\n",
      "[9, 6000] loss: 1.324260446190834\n",
      "[9, 7000] loss: 1.2786828345954417\n",
      "[9, 8000] loss: 1.3167451583743095\n",
      "[9, 9000] loss: 1.2943515675961972\n",
      "Test Loss: 1.3634517507743835\n",
      "[10, 1000] loss: 1.2550244828760624\n",
      "[10, 2000] loss: 1.2702865155041219\n",
      "[10, 3000] loss: 1.2788388261795043\n",
      "[10, 4000] loss: 1.2854693731367588\n",
      "[10, 5000] loss: 1.2755249813497067\n",
      "[10, 6000] loss: 1.2835638642907143\n",
      "[10, 7000] loss: 1.268633427798748\n",
      "[10, 8000] loss: 1.2811226629912853\n",
      "[10, 9000] loss: 1.2799672189056874\n",
      "Test Loss: 1.3889548688983917\n"
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:13:15.890876Z",
     "start_time": "2019-03-19T18:11:21.640670Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] loss: 1.2213223802745343\n",
      "[1, 2000] loss: 1.1805383367836475\n",
      "[1, 3000] loss: 1.139053843408823\n",
      "[1, 4000] loss: 1.1851782874763013\n",
      "[1, 5000] loss: 1.1985605453252792\n",
      "[1, 6000] loss: 1.169822973549366\n",
      "[1, 7000] loss: 1.191998456954956\n",
      "[1, 8000] loss: 1.1771617861986161\n",
      "[1, 9000] loss: 1.1685627602934838\n",
      "Test Loss: 1.3114385506248474\n",
      "[2, 1000] loss: 1.1707515446543693\n",
      "[2, 2000] loss: 1.1656533801555633\n",
      "[2, 3000] loss: 1.1393925215303897\n",
      "[2, 4000] loss: 1.1863460129499435\n",
      "[2, 5000] loss: 1.1807792509794235\n",
      "[2, 6000] loss: 1.1562031549811362\n",
      "[2, 7000] loss: 1.1528634119033814\n",
      "[2, 8000] loss: 1.1906743482649327\n",
      "[2, 9000] loss: 1.1841574289798737\n",
      "Test Loss: 1.3104818570041656\n",
      "[3, 1000] loss: 1.1668889275491237\n",
      "[3, 2000] loss: 1.1750831956267356\n",
      "[3, 3000] loss: 1.1272694622576236\n",
      "[3, 4000] loss: 1.1672408270537853\n",
      "[3, 5000] loss: 1.1675383879840373\n",
      "[3, 6000] loss: 1.151933901399374\n",
      "[3, 7000] loss: 1.154692899554968\n",
      "[3, 8000] loss: 1.1852463311254977\n",
      "[3, 9000] loss: 1.1885173217356204\n",
      "Test Loss: 1.311621836900711\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.000001,\n",
    "                      momentum=0.9, weight_decay=0.00001)\n",
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:14:44.593158Z",
     "start_time": "2019-03-19T18:14:44.582031Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/CIFAR10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:20:42.652750Z",
     "start_time": "2019-03-19T18:18:29.836644Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] loss: 1.1734067938923836\n",
      "[1, 2000] loss: 1.1356912103891372\n",
      "[1, 3000] loss: 1.1721566995382309\n",
      "[1, 4000] loss: 1.1517045343816281\n",
      "[1, 5000] loss: 1.1564928091168403\n",
      "[1, 6000] loss: 1.153905338048935\n",
      "[1, 7000] loss: 1.1609659651219846\n",
      "[1, 8000] loss: 1.156905490398407\n",
      "[1, 9000] loss: 1.1751214535832406\n",
      "Test Loss: 1.3026150169849395\n",
      "[2, 1000] loss: 1.1549373888373375\n",
      "[2, 2000] loss: 1.1627117763459682\n",
      "[2, 3000] loss: 1.1570463382303715\n",
      "[2, 4000] loss: 1.1412937308847904\n",
      "[2, 5000] loss: 1.1585473252534866\n",
      "[2, 6000] loss: 1.157166733443737\n",
      "[2, 7000] loss: 1.1884651707708835\n",
      "[2, 8000] loss: 1.1400272831618785\n",
      "[2, 9000] loss: 1.1451120183765888\n",
      "Test Loss: 1.3047532446193695\n",
      "[3, 1000] loss: 1.1618755494356154\n",
      "[3, 2000] loss: 1.1068300998210907\n",
      "[3, 3000] loss: 1.1816344597041606\n",
      "[3, 4000] loss: 1.1490236032307148\n",
      "[3, 5000] loss: 1.148387181609869\n",
      "[3, 6000] loss: 1.1568145793676377\n",
      "[3, 7000] loss: 1.133525220811367\n",
      "[3, 8000] loss: 1.1476807802915574\n",
      "[3, 9000] loss: 1.1606893203258515\n",
      "Test Loss: 1.302482350692749\n"
     ]
    }
   ],
   "source": [
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:25:47.564312Z",
     "start_time": "2019-03-19T18:22:09.187650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000] loss: 1.1612608671784401\n",
      "[1, 2000] loss: 1.1143279196321965\n",
      "[1, 3000] loss: 1.1386787248849868\n",
      "[1, 4000] loss: 1.1371249536573886\n",
      "[1, 5000] loss: 1.1682247643768788\n",
      "[1, 6000] loss: 1.1708780645132064\n",
      "[1, 7000] loss: 1.1531031126379967\n",
      "[1, 8000] loss: 1.1541125074028968\n",
      "[1, 9000] loss: 1.129371852427721\n",
      "Test Loss: 1.301788368244171\n",
      "[2, 1000] loss: 1.1239619280695916\n",
      "[2, 2000] loss: 1.1447209930717945\n",
      "[2, 3000] loss: 1.1432888792455196\n",
      "[2, 4000] loss: 1.1287364637553692\n",
      "[2, 5000] loss: 1.1373072642087936\n",
      "[2, 6000] loss: 1.150818851441145\n",
      "[2, 7000] loss: 1.188343494385481\n",
      "[2, 8000] loss: 1.128650383144617\n",
      "[2, 9000] loss: 1.1448564236462115\n",
      "Test Loss: 1.3067093565654755\n",
      "[3, 1000] loss: 1.1244019352793693\n",
      "[3, 2000] loss: 1.1273026388287544\n",
      "[3, 3000] loss: 1.1394866808652877\n",
      "[3, 4000] loss: 1.1009647597074508\n",
      "[3, 5000] loss: 1.1343373363614082\n",
      "[3, 6000] loss: 1.15392905575037\n",
      "[3, 7000] loss: 1.1436365436315536\n",
      "[3, 8000] loss: 1.1543157762289047\n",
      "[3, 9000] loss: 1.1501931378245354\n",
      "Test Loss: 1.2997300477409364\n",
      "[4, 1000] loss: 1.1813841313719748\n",
      "[4, 2000] loss: 1.143110434025526\n",
      "[4, 3000] loss: 1.1204481443166734\n",
      "[4, 4000] loss: 1.1231878345906734\n",
      "[4, 5000] loss: 1.1482505472004414\n",
      "[4, 6000] loss: 1.1035277628302573\n",
      "[4, 7000] loss: 1.1016645064651966\n",
      "[4, 8000] loss: 1.1609301384091377\n",
      "[4, 9000] loss: 1.1304738767147064\n",
      "Test Loss: 1.2941147240829467\n",
      "[5, 1000] loss: 1.1391114771962165\n",
      "[5, 2000] loss: 1.1283513169586659\n",
      "[5, 3000] loss: 1.12300508877635\n",
      "[5, 4000] loss: 1.1242658665776253\n",
      "[5, 5000] loss: 1.1278473705649377\n",
      "[5, 6000] loss: 1.144517223805189\n",
      "[5, 7000] loss: 1.1164429484009744\n",
      "[5, 8000] loss: 1.1396472214460374\n",
      "[5, 9000] loss: 1.1403023747205734\n",
      "Test Loss: 1.2954137623977662\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T18:26:49.366305Z",
     "start_time": "2019-03-19T18:26:49.359577Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/CIFAR10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
